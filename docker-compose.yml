version: "3.8"
networks:
  ai-services:
    driver: bridge
  traefik:
    external: true
    name: ${TRAEFIK_NETWORK:-traefik_default}
volumes:
  comfyui-data: null
  invokeai-data: null
  dockge-data: null
  dockge-stacks: null
services:
  # ============================================
  # ComfyUI - AI Image Generation
  # ============================================
  comfyui:
    # Using YanWenKun's ComfyUI image (correct repository name)
    # Repository: https://github.com/YanWenKun/ComfyUI-Docker
    # Using cu121-megapak - CUDA 12.1 has better flash-attention compatibility with RTX 6000 Ada
    # cu128 and cu124 both had flash-attention errors (flash_fwd_launch_template.h:180)
    image: ${COMFYUI_IMAGE:-yanwk/comfyui-boot:cu121-megapak}
    container_name: dhoch3-comfyui
    restart: unless-stopped
    networks:
      - traefik
      - ai-services
    ports:
      - ${COMFYUI_PORT:-8188}:8188
    volumes:
      # Shared models (READ-ONLY)
      - ${MODELS_PATH:-/vol/service/cw/storage-models/models}:/root/ComfyUI/models
      # Service data
      - comfyui-data:/app/ComfyUI
      # User outputs
      - ${USER_STORAGE_PATH:-/vol/service/cw/storage-user}/output/ComfyUI:/root/ComfyUI/output
      # User inputs (READ-ONLY)
      - ${USER_STORAGE_PATH:-/vol/service/cw/storage-user}/input:/root/ComfyUI/input
      # Workflows
      - ${USER_STORAGE_PATH:-/vol/service/cw/storage-user}/workflows:/root/ComfyUI/user/default/workflows
    environment:
      - NVIDIA_VISIBLE_DEVICES=${NVIDIA_VISIBLE_DEVICES:-all}
      - CUDA_VISIBLE_DEVICES=${CUDA_VISIBLE_DEVICES:-0}
      # Disable flash-attention to avoid CUDA errors on RTX 6000 Ada
      - XFORMERS_FORCE_DISABLE_TRITON=1
      # Better CUDA memory management
      - PYTORCH_CUDA_ALLOC_CONF=max_split_size_mb:512
    deploy:
      resources:
        reservations:
          devices:
            - driver: nvidia
              count: all
              capabilities:
                - gpu
    labels:
      - traefik.enable=true
      - traefik.docker.network=${TRAEFIK_NETWORK:-traefik_default}
      # HTTP Router
      - traefik.http.routers.comfyui.entrypoints=websecure
      - traefik.http.routers.comfyui.rule=Host(`${COMFYUI_SUBDOMAIN:-comfyui}.${DOMAIN}`)
      - traefik.http.routers.comfyui.tls=true
      - traefik.http.routers.comfyui.tls.certresolver=${CERT_RESOLVER:-letsencryptresolver}
      - traefik.http.routers.comfyui.middlewares=${TRAEFIK_MIDDLEWARE:-default@file}
      - traefik.http.services.comfyui.loadbalancer.server.port=8188
  # ============================================
  # Fooocus - AI Image Generation
  # ============================================
  fooocus:
    build:
      context: ./dockerfiles/fooocus
      dockerfile: Dockerfile
    image: dhoch3/fooocus:latest
    container_name: dhoch3-fooocus
    restart: unless-stopped
    networks:
      - traefik
      - ai-services
    ports:
      - ${FOOOCUS_PORT:-7860}:7860
    volumes:
      # Shared models (READ-ONLY)
      - ${MODELS_PATH:-/vol/service/cw/storage-models/models}:/root/models
      # User outputs
      - ${USER_STORAGE_PATH:-/vol/service/cw/storage-user}/output/Fooocus:/root/outputs
      # User inputs (READ-ONLY)
      #- ${USER_STORAGE_PATH:-/vol/service/cw/storage-user}/input:/inputs:ro
    environment:
      - NVIDIA_VISIBLE_DEVICES=${NVIDIA_VISIBLE_DEVICES:-all}
      - CUDA_VISIBLE_DEVICES=${CUDA_VISIBLE_DEVICES:-0}
    deploy:
      resources:
        reservations:
          devices:
            - driver: nvidia
              count: all
              capabilities:
                - gpu
    labels:
      - traefik.enable=true
      - traefik.docker.network=${TRAEFIK_NETWORK:-traefik_default}
      # HTTP Router
      - traefik.http.routers.fooocus.entrypoints=websecure
      - traefik.http.routers.fooocus.rule=Host(`${FOOOCUS_SUBDOMAIN:-fooocus}.${DOMAIN}`)
      - traefik.http.routers.fooocus.tls=true
      - traefik.http.routers.fooocus.tls.certresolver=${CERT_RESOLVER:-letsencryptresolver}
      - traefik.http.routers.fooocus.middlewares=${TRAEFIK_MIDDLEWARE:-default@file}
      - traefik.http.services.fooocus.loadbalancer.server.port=7860
  # ============================================
  # Reforge Neo - Stable Diffusion WebUI Forge Classic (Neo Branch)
  # ============================================
  forge:
    build:
      context: ./dockerfiles/forge
      dockerfile: Dockerfile
    image: dhoch3/forge:latest
    container_name: dhoch3-forge
    restart: unless-stopped
    networks:
      - traefik
      - ai-services
    ports:
      - ${FORGE_PORT:-7861}:7861
    volumes:
      # Shared models (READ-ONLY)
      - ${MODELS_PATH:-/vol/service/cw/storage-models/models}:/models:ro
      # User outputs
      - ${USER_STORAGE_PATH:-/vol/service/cw/storage-user}/output/Forge:/outputs
      # User inputs (READ-ONLY)
      - ${USER_STORAGE_PATH:-/vol/service/cw/storage-user}/input:/inputs:ro
    environment:
      - NVIDIA_VISIBLE_DEVICES=${NVIDIA_VISIBLE_DEVICES:-all}
      - CUDA_VISIBLE_DEVICES=${CUDA_VISIBLE_DEVICES:-0}
    deploy:
      resources:
        reservations:
          devices:
            - driver: nvidia
              count: all
              capabilities:
                - gpu
    labels:
      - traefik.enable=true
      - traefik.docker.network=${TRAEFIK_NETWORK:-traefik_default}
      # HTTP Router
      - traefik.http.routers.forge.entrypoints=websecure
      - traefik.http.routers.forge.rule=Host(`${FORGE_SUBDOMAIN:-forge}.${DOMAIN}`)
      - traefik.http.routers.forge.tls=true
      - traefik.http.routers.forge.tls.certresolver=${CERT_RESOLVER:-letsencryptresolver}
      - traefik.http.routers.forge.middlewares=${TRAEFIK_MIDDLEWARE:-default@file}
      - traefik.http.services.forge.loadbalancer.server.port=7861
  # ============================================
  # InvokeAI - AI Image Generation
  # ============================================
  invokeai:
    image: ${INVOKEAI_IMAGE:-ghcr.io/invoke-ai/invokeai:latest}
    container_name: dhoch3-invokeai
    restart: unless-stopped
    networks:
      - traefik
      - ai-services
    ports:
      - ${INVOKEAI_PORT:-9090}:9090
    volumes:
      # Shared models (READ-ONLY)
      - ${MODELS_PATH:-/vol/service/cw/storage-models/models}:/root/models:ro
      # Service data
      - invokeai-data:/invokeai
      # User outputs
      - ${USER_STORAGE_PATH:-/vol/service/cw/storage-user}/output/InvokeAI:/outputs
      # User inputs (READ-ONLY)
      - ${USER_STORAGE_PATH:-/vol/service/cw/storage-user}/input:/inputs:ro
    environment:
      - NVIDIA_VISIBLE_DEVICES=${NVIDIA_VISIBLE_DEVICES:-all}
      - CUDA_VISIBLE_DEVICES=${CUDA_VISIBLE_DEVICES:-0}
    deploy:
      resources:
        reservations:
          devices:
            - driver: nvidia
              count: all
              capabilities:
                - gpu
    labels:
      - traefik.enable=true
      - traefik.docker.network=${TRAEFIK_NETWORK:-traefik_default}
      # HTTP Router
      - traefik.http.routers.invokeai.entrypoints=websecure
      - traefik.http.routers.invokeai.rule=Host(`${INVOKEAI_SUBDOMAIN:-invokeai}.${DOMAIN}`)
      - traefik.http.routers.invokeai.tls=true
      - traefik.http.routers.invokeai.tls.certresolver=${CERT_RESOLVER:-letsencryptresolver}
      - traefik.http.routers.invokeai.middlewares=${TRAEFIK_MIDDLEWARE:-default@file}
      - traefik.http.services.invokeai.loadbalancer.server.port=9090

  # ============================================
  # AI Toolkit - AI Training Tools with Web UI
  # ============================================
  ai-toolkit:
    build:
      context: ./dockerfiles/ai-toolkit
      dockerfile: Dockerfile
    image: dhoch3/ai-toolkit:latest
    container_name: dhoch3-ai-toolkit
    restart: unless-stopped
    networks:
      - traefik
      - ai-services
    ports:
      - ${AI_TOOLKIT_PORT:-8675}:8675
    volumes:
      # Shared models (READ-ONLY)
      - ${MODELS_PATH:-/vol/service/cw/storage-models/models}:/models:ro
      # Training outputs
      - ${USER_STORAGE_PATH:-/vol/service/cw/storage-user}/output/AIToolkit:/outputs
      # Training datasets (READ-ONLY)
      - ${USER_STORAGE_PATH:-/vol/service/cw/storage-user}/input:/datasets:ro
      # Workflows
      - ${USER_STORAGE_PATH:-/vol/service/cw/storage-user}/workflows:/workflows
    environment:
      - NVIDIA_VISIBLE_DEVICES=${NVIDIA_VISIBLE_DEVICES:-all}
      - CUDA_VISIBLE_DEVICES=${CUDA_VISIBLE_DEVICES:-0}
    deploy:
      resources:
        reservations:
          devices:
            - driver: nvidia
              count: all
              capabilities:
                - gpu
    labels:
      - traefik.enable=true
      - traefik.docker.network=${TRAEFIK_NETWORK:-traefik_default}
      # HTTP Router
      - traefik.http.routers.ai-toolkit.entrypoints=websecure
      - traefik.http.routers.ai-toolkit.rule=Host(`${AI_TOOLKIT_SUBDOMAIN:-ai-toolkit}.${DOMAIN}`)
      - traefik.http.routers.ai-toolkit.tls=true
      - traefik.http.routers.ai-toolkit.tls.certresolver=${CERT_RESOLVER:-letsencryptresolver}
      - traefik.http.routers.ai-toolkit.middlewares=${TRAEFIK_MIDDLEWARE:-default@file}
      - traefik.http.services.ai-toolkit.loadbalancer.server.port=8675
  # ============================================
  # Dockge - Container Management UI
  # ============================================
  dockge:
    image: ${DOCKGE_IMAGE:-louislam/dockge:latest}
    container_name: dhoch3-dockge
    restart: unless-stopped
    networks:
      - traefik
      - ai-services
    ports:
      - ${DOCKGE_PORT:-5001}:5001
    volumes:
      - /var/run/docker.sock:/var/run/docker.sock:ro
      - dockge-data:/app/data
      - dockge-stacks:/opt/stacks
      - ${PWD}:/opt/stacks/dhoch3-ai-services
    environment:
      - DOCKGE_STACKS_DIR=/opt/stacks
    labels:
      - traefik.enable=true
      - traefik.docker.network=${TRAEFIK_NETWORK:-traefik_default}
      # HTTP Router
      - traefik.http.routers.dockge.entrypoints=websecure
      - traefik.http.routers.dockge.rule=Host(`${DOCKGE_SUBDOMAIN:-dockge}.${DOMAIN}`)
      - traefik.http.routers.dockge.tls=true
      - traefik.http.routers.dockge.tls.certresolver=${CERT_RESOLVER:-letsencryptresolver}
      - traefik.http.routers.dockge.middlewares=${TRAEFIK_MIDDLEWARE:-admin-auth@file,default@file}
      - traefik.http.routers.dockge.priority=1000
      - traefik.http.services.dockge.loadbalancer.server.port=5001
