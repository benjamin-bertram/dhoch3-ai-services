# dhoch3-ai-services Environment Configuration
# Copy this file to .env and fill in your actual values
# DO NOT commit .env to git!

# ============================================
# SMB Storage Configuration
# ============================================
SMB_SERVER=192.168.0.6
SMB_SHARE=ki_Daten
SMB_USER=d3kiserver
SMB_PASSWORD=your_smb_password_here

# SMB Mount Options
SMB_VERSION=3.0
SMB_MOUNT_OPTIONS=vers=3.0,credentials=/etc/samba/credentials,uid=1000,gid=1000

# ============================================
# Storage Paths
# ============================================
# Shared model storage (READ-ONLY for all services)
MODELS_PATH=/vol/service/cw/storage-models/models

# Service-specific data storage
STORAGE_PATH=/vol/service/cw/storage

# User data storage (inputs, outputs, workflows)
USER_STORAGE_PATH=/vol/service/cw/storage-user

# ============================================
# Domain Configuration
# ============================================
DOMAIN=design-hoch-drei.de

# Service Subdomains
COMFYUI_SUBDOMAIN=comfyui
FOOOCUS_SUBDOMAIN=fooocus
FORGE_SUBDOMAIN=forge
INVOKEAI_SUBDOMAIN=invokeai
FLUXGYM_SUBDOMAIN=fluxgym
AI_TOOLKIT_SUBDOMAIN=ai-toolkit
DOCKGE_SUBDOMAIN=dockge

# ============================================
# Service Ports (Internal)
# ============================================
COMFYUI_PORT=8188
FOOOCUS_PORT=7860
FORGE_PORT=7861
INVOKEAI_PORT=9090
FLUXGYM_PORT=3000
AI_TOOLKIT_PORT=8080
DOCKGE_PORT=5001

# ============================================
# Ollama Configuration (Native)
# ============================================
OLLAMA_HOST=localhost
OLLAMA_PORT=11434

# ============================================
# GPU Configuration
# ============================================
NVIDIA_VISIBLE_DEVICES=all
CUDA_VISIBLE_DEVICES=0

# ============================================
# Docker Configuration
# ============================================
COMPOSE_PROJECT_NAME=dhoch3-ai-services
DOCKER_BUILDKIT=1

# ============================================
# Traefik Configuration
# ============================================
# Network name (must match your Traefik network)
TRAEFIK_NETWORK=base

# Certificate resolver name (from Traefik config)
CERT_RESOLVER=letsencryptresolver

# Middleware for authentication and security
# Options: default@file, admin-auth@file, or custom middleware
TRAEFIK_MIDDLEWARE=default@file

# ============================================
# User/Group IDs (for file permissions)
# ============================================
PUID=1000
PGID=1000

# ============================================
# Service-Specific Configuration
# ============================================

# ComfyUI
# Repository: https://github.com/YanWenKun/ComfyUI-Docker
# Options:
#   - yanwk/comfyui-boot:cu128-megapak (CUDA 12.8, all-in-one with custom nodes)
#   - yanwk/comfyui-boot:cu128-slim (CUDA 12.8, minimal install)
#   - yanwk/comfyui-boot:cu128-megapak-pt28 (CUDA 12.8, PyTorch 2.8)
COMFYUI_IMAGE=yanwk/comfyui-boot:cu128-megapak

# InvokeAI
INVOKEAI_IMAGE=ghcr.io/invoke-ai/invokeai:latest

# Dockge
DOCKGE_IMAGE=louislam/dockge:latest

# ============================================
# Build Configuration
# ============================================
CUDA_VERSION=12.1.0
PYTHON_VERSION=3.10
PYTORCH_VERSION=2.1.0

